"Issue Type","Summary","Test Type","Gherkin","Labels"
"Test","Filter records older than 60 days","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given the MySQL database is accessible\n    And the 'run' table contains records with 'msg_sent_date' in epoch ms\n  Scenario: Filter records older than 60 days\n    When the archival script is executed\n    Then only records with 'msg_sent_date' older than 60 days are selected","DEV-1017"
"Test","Export filtered records to CSV with correct naming","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given filtered records are available\n  Scenario: Export to CSV\n    When the script exports the records\n    Then the CSV file is named 'run_archive_YYYYMMDD.csv'\n    And the file contains all filtered records","DEV-1017"
"Test","Upload CSV to correct S3 location","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given a CSV file 'run_archive_YYYYMMDD.csv' exists\n    And the S3 bucket and folder are configured\n  Scenario: Upload to S3\n    When the script uploads the file\n    Then the file appears in the correct S3 bucket and folder","DEV-1017"
"Test","Delete records only after successful S3 upload","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given filtered records are exported and S3 upload is attempted\n  Scenario: Conditional deletion\n    When the S3 upload is successful\n    Then the corresponding records are deleted from the 'run' table\n    But if the upload fails, no records are deleted","DEV-1017"
"Test","Verify data integrity between DB and CSV before deletion","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given filtered records are exported to CSV\n  Scenario: Data integrity check\n    When the CSV is compared to the DB records before deletion\n    Then all fields and record counts must match","DEV-1017"
"Test","Log archival process and automate with cron","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given the archival script is scheduled with cron\n  Scenario: Logging and automation\n    When the script runs\n    Then a log file is created with details of each step and errors (if any)","DEV-1017"
"Test","Optionally archive records to run_archive table","Cucumber","Feature: Archive & Upload 60 Days Old Run Data to S3\n  Background:\n    Given the 'run_archive' table exists\n  Scenario: Archive to run_archive table\n    When the script is configured to archive\n    Then filtered records are inserted into 'run_archive' before deletion","DEV-1017" 